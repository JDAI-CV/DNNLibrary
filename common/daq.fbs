namespace DNN;

/// Int8 is deprecated, but int8_data in table Tensor is used, since a Tensor just stores value, not care about quantization method
enum DataType:byte { Float32 = 0, Int8, Int32, Float16, Bool8,
    QUANT8_ASYMM, QUANT8_SYMM, QUANT8_SYMM_PER_CHANNEL, 
    QUANT16_ASYMM, QUANT16_SYMM}
enum FuseCode:byte { None = 0, Relu, Relu1, Relu6 }
enum LayerType:byte { Conv2D = 0, AvePool, MaxPool, Relu, Softmax, FC, Add, Concat,
    DepthwiseConv2D, BatchToSpace, SpaceToBatch, StridedSlice, Mul, AddScalar, MulScalar,
    Dequantize, LRN}

table Tensor {
    data_type:DataType;
    int8_data: [uint8];
    float32_data: [float32];
    shape: [uint32];
    name: string;
    /// since flatbuffers doesn't have float16 data type, use uint16 instead
    float16_data: [uint16];
    bool8_data: [uint8];
    int32_data: [int32];
}

/// For weights, and for features
table QuantInfo {
    name: string;
    data_type: DataType;
    /// a float32 array of scales, the length will be 1 for non per-channel quantization, and be channelDim for per-channel quantization
    scales: [float32];
    zero_point: int32;
}

table Input {
    shape:[uint32];
    name:string;
}

table StridedSlice {
    input:string;
    starts:[int];
    ends:[int];
    strides:[int];
    begin_mask:int;
    end_mask:int;
    shrink_axis_mask:int;
    output:string;
}

table BatchToSpace {
    input:string;
    block_sizes:[int];
    output:string;
}

table SpaceToBatch {
    input:string;
    block_sizes:[int];
    pads:[int];
    output:string;
}

table Conv2D {
    input:string;
    weight:string;
    bias:string;
    pads:[int];
    strides:[int];
    fuse:FuseCode;
    output:string;
}

table DepthwiseConv2D {
    input:string;
    weight:string;
    bias:string;
    pads:[int];
    strides:[int];
    multiplier:int;
    fuse:FuseCode;
    output:string;
}

table AvePool {
    input:string;
    kernel_shape:[int];
    pads:[int];
    strides:[int];
    fuse:FuseCode;
    output:string;
}

table MaxPool {
    input:string;
    kernel_shape:[int];
    pads:[int];
    strides:[int];
    fuse:FuseCode;
    output:string;
}

table Relu {
    input:string;
    output:string;
}

table Softmax {
    input:string;
    output:string;
}

table FC {
    input:string;
    weight:string;
    bias:string;
    fuse:FuseCode;
    output:string;
}

table Add {
    input1:string;
    input2:string;
    fuse:FuseCode;
    output:string;
}

table Concat {
    inputs:[string];
    axis:int;
    output:string;
}

table Mul {
    input1:string;
    input2:string;
    fuse:FuseCode;
    output:string;
}

table AddScalar {
    input1:string;
    input2:float;
    fuse:FuseCode;
    output:string;
}

table MulScalar {
    input1:string;
    input2:float;
    fuse:FuseCode;
    output:string;
}

table Dequantize {
    input:string;
    output:string;
}

table LRN {
    input:string;
    radius:int;
    bias:float;
    alpha:float;
    beta:float;
    output:string;
}

table Layer {
    type:LayerType;
    conv2d_param:Conv2D;
    avepool_param:AvePool;
    maxpool_param:MaxPool;
    relu_param:Relu;
    softmax_param:Softmax;
    fc_param:FC;
    add_param:Add;
    concat_param:Concat;
    depthwise_conv2d_param:DepthwiseConv2D;
    batch_to_space_param:BatchToSpace;
    space_to_batch_param:SpaceToBatch;
    strided_slice_param:StridedSlice;
    mul_param:Mul;
    add_scalar_param:AddScalar;
    mul_scalar_param:MulScalar;
    dequantize_param:Dequantize;
    lrn_param:LRN;
}

table Model {
    layers:[Layer];
    initializers:[Tensor];
    inputs:[Input];
    quant_infos:[QuantInfo];
}

root_type Model;

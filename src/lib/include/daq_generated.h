// automatically generated by the FlatBuffers compiler, do not modify


#ifndef FLATBUFFERS_GENERATED_DAQ_DNN_H_
#define FLATBUFFERS_GENERATED_DAQ_DNN_H_

#include "flatbuffers/flatbuffers.h"

namespace DNN {

struct Tensor;

struct Input;

struct StridedSlice;

struct BatchToSpace;

struct SpaceToBatch;

struct Conv2D;

struct DepthwiseConv2D;

struct AvePool;

struct MaxPool;

struct Relu;

struct Softmax;

struct FC;

struct Add;

struct Concat;

struct Layer;

struct Model;

enum class DataType : int8_t {
  Float32 = 0,
  Int8 = 1,
  MIN = Float32,
  MAX = Int8
};

inline const DataType (&EnumValuesDataType())[2] {
  static const DataType values[] = {
    DataType::Float32,
    DataType::Int8
  };
  return values;
}

inline const char * const *EnumNamesDataType() {
  static const char * const names[] = {
    "Float32",
    "Int8",
    nullptr
  };
  return names;
}

inline const char *EnumNameDataType(DataType e) {
  const size_t index = static_cast<int>(e);
  return EnumNamesDataType()[index];
}

enum class FuseCode : int8_t {
  None = 0,
  Relu = 1,
  Relu1 = 2,
  Relu6 = 3,
  MIN = None,
  MAX = Relu6
};

inline const FuseCode (&EnumValuesFuseCode())[4] {
  static const FuseCode values[] = {
    FuseCode::None,
    FuseCode::Relu,
    FuseCode::Relu1,
    FuseCode::Relu6
  };
  return values;
}

inline const char * const *EnumNamesFuseCode() {
  static const char * const names[] = {
    "None",
    "Relu",
    "Relu1",
    "Relu6",
    nullptr
  };
  return names;
}

inline const char *EnumNameFuseCode(FuseCode e) {
  const size_t index = static_cast<int>(e);
  return EnumNamesFuseCode()[index];
}

enum class LayerType : int8_t {
  Conv2D = 0,
  AvePool = 1,
  MaxPool = 2,
  Relu = 3,
  Softmax = 4,
  FC = 5,
  Add = 6,
  Concat = 7,
  DepthwiseConv2D = 8,
  BatchToSpace = 9,
  SpaceToBatch = 10,
  StridedSlice = 11,
  MIN = Conv2D,
  MAX = StridedSlice
};

inline const LayerType (&EnumValuesLayerType())[12] {
  static const LayerType values[] = {
    LayerType::Conv2D,
    LayerType::AvePool,
    LayerType::MaxPool,
    LayerType::Relu,
    LayerType::Softmax,
    LayerType::FC,
    LayerType::Add,
    LayerType::Concat,
    LayerType::DepthwiseConv2D,
    LayerType::BatchToSpace,
    LayerType::SpaceToBatch,
    LayerType::StridedSlice
  };
  return values;
}

inline const char * const *EnumNamesLayerType() {
  static const char * const names[] = {
    "Conv2D",
    "AvePool",
    "MaxPool",
    "Relu",
    "Softmax",
    "FC",
    "Add",
    "Concat",
    "DepthwiseConv2D",
    "BatchToSpace",
    "SpaceToBatch",
    "StridedSlice",
    nullptr
  };
  return names;
}

inline const char *EnumNameLayerType(LayerType e) {
  const size_t index = static_cast<int>(e);
  return EnumNamesLayerType()[index];
}

struct Tensor FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_DATA_TYPE = 4,
    VT_INT8_DATA = 6,
    VT_FLOAT32_DATA = 8,
    VT_SHAPE = 10,
    VT_NAME = 12
  };
  DataType data_type() const {
    return static_cast<DataType>(GetField<int8_t>(VT_DATA_TYPE, 0));
  }
  const flatbuffers::Vector<uint8_t> *int8_data() const {
    return GetPointer<const flatbuffers::Vector<uint8_t> *>(VT_INT8_DATA);
  }
  const flatbuffers::Vector<float> *float32_data() const {
    return GetPointer<const flatbuffers::Vector<float> *>(VT_FLOAT32_DATA);
  }
  const flatbuffers::Vector<uint32_t> *shape() const {
    return GetPointer<const flatbuffers::Vector<uint32_t> *>(VT_SHAPE);
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, VT_DATA_TYPE) &&
           VerifyOffset(verifier, VT_INT8_DATA) &&
           verifier.VerifyVector(int8_data()) &&
           VerifyOffset(verifier, VT_FLOAT32_DATA) &&
           verifier.VerifyVector(float32_data()) &&
           VerifyOffset(verifier, VT_SHAPE) &&
           verifier.VerifyVector(shape()) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           verifier.EndTable();
  }
};

struct TensorBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_data_type(DataType data_type) {
    fbb_.AddElement<int8_t>(Tensor::VT_DATA_TYPE, static_cast<int8_t>(data_type), 0);
  }
  void add_int8_data(flatbuffers::Offset<flatbuffers::Vector<uint8_t>> int8_data) {
    fbb_.AddOffset(Tensor::VT_INT8_DATA, int8_data);
  }
  void add_float32_data(flatbuffers::Offset<flatbuffers::Vector<float>> float32_data) {
    fbb_.AddOffset(Tensor::VT_FLOAT32_DATA, float32_data);
  }
  void add_shape(flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape) {
    fbb_.AddOffset(Tensor::VT_SHAPE, shape);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Tensor::VT_NAME, name);
  }
  explicit TensorBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  TensorBuilder &operator=(const TensorBuilder &);
  flatbuffers::Offset<Tensor> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Tensor>(end);
    return o;
  }
};

inline flatbuffers::Offset<Tensor> CreateTensor(
    flatbuffers::FlatBufferBuilder &_fbb,
    DataType data_type = DataType::Float32,
    flatbuffers::Offset<flatbuffers::Vector<uint8_t>> int8_data = 0,
    flatbuffers::Offset<flatbuffers::Vector<float>> float32_data = 0,
    flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0) {
  TensorBuilder builder_(_fbb);
  builder_.add_name(name);
  builder_.add_shape(shape);
  builder_.add_float32_data(float32_data);
  builder_.add_int8_data(int8_data);
  builder_.add_data_type(data_type);
  return builder_.Finish();
}

inline flatbuffers::Offset<Tensor> CreateTensorDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    DataType data_type = DataType::Float32,
    const std::vector<uint8_t> *int8_data = nullptr,
    const std::vector<float> *float32_data = nullptr,
    const std::vector<uint32_t> *shape = nullptr,
    const char *name = nullptr) {
  return DNN::CreateTensor(
      _fbb,
      data_type,
      int8_data ? _fbb.CreateVector<uint8_t>(*int8_data) : 0,
      float32_data ? _fbb.CreateVector<float>(*float32_data) : 0,
      shape ? _fbb.CreateVector<uint32_t>(*shape) : 0,
      name ? _fbb.CreateString(name) : 0);
}

struct Input FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_SHAPE = 4,
    VT_NAME = 6
  };
  const flatbuffers::Vector<uint32_t> *shape() const {
    return GetPointer<const flatbuffers::Vector<uint32_t> *>(VT_SHAPE);
  }
  const flatbuffers::String *name() const {
    return GetPointer<const flatbuffers::String *>(VT_NAME);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_SHAPE) &&
           verifier.VerifyVector(shape()) &&
           VerifyOffset(verifier, VT_NAME) &&
           verifier.VerifyString(name()) &&
           verifier.EndTable();
  }
};

struct InputBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_shape(flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape) {
    fbb_.AddOffset(Input::VT_SHAPE, shape);
  }
  void add_name(flatbuffers::Offset<flatbuffers::String> name) {
    fbb_.AddOffset(Input::VT_NAME, name);
  }
  explicit InputBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  InputBuilder &operator=(const InputBuilder &);
  flatbuffers::Offset<Input> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Input>(end);
    return o;
  }
};

inline flatbuffers::Offset<Input> CreateInput(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<uint32_t>> shape = 0,
    flatbuffers::Offset<flatbuffers::String> name = 0) {
  InputBuilder builder_(_fbb);
  builder_.add_name(name);
  builder_.add_shape(shape);
  return builder_.Finish();
}

inline flatbuffers::Offset<Input> CreateInputDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<uint32_t> *shape = nullptr,
    const char *name = nullptr) {
  return DNN::CreateInput(
      _fbb,
      shape ? _fbb.CreateVector<uint32_t>(*shape) : 0,
      name ? _fbb.CreateString(name) : 0);
}

struct StridedSlice FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_STARTS = 6,
    VT_ENDS = 8,
    VT_STRIDES = 10,
    VT_BEGIN_MASK = 12,
    VT_END_MASK = 14,
    VT_SHRINK_AXIS_MASK = 16,
    VT_OUTPUT = 18
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *starts() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STARTS);
  }
  const flatbuffers::Vector<int32_t> *ends() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_ENDS);
  }
  const flatbuffers::Vector<int32_t> *strides() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDES);
  }
  int32_t begin_mask() const {
    return GetField<int32_t>(VT_BEGIN_MASK, 0);
  }
  int32_t end_mask() const {
    return GetField<int32_t>(VT_END_MASK, 0);
  }
  int32_t shrink_axis_mask() const {
    return GetField<int32_t>(VT_SHRINK_AXIS_MASK, 0);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_STARTS) &&
           verifier.VerifyVector(starts()) &&
           VerifyOffset(verifier, VT_ENDS) &&
           verifier.VerifyVector(ends()) &&
           VerifyOffset(verifier, VT_STRIDES) &&
           verifier.VerifyVector(strides()) &&
           VerifyField<int32_t>(verifier, VT_BEGIN_MASK) &&
           VerifyField<int32_t>(verifier, VT_END_MASK) &&
           VerifyField<int32_t>(verifier, VT_SHRINK_AXIS_MASK) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct StridedSliceBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(StridedSlice::VT_INPUT, input);
  }
  void add_starts(flatbuffers::Offset<flatbuffers::Vector<int32_t>> starts) {
    fbb_.AddOffset(StridedSlice::VT_STARTS, starts);
  }
  void add_ends(flatbuffers::Offset<flatbuffers::Vector<int32_t>> ends) {
    fbb_.AddOffset(StridedSlice::VT_ENDS, ends);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides) {
    fbb_.AddOffset(StridedSlice::VT_STRIDES, strides);
  }
  void add_begin_mask(int32_t begin_mask) {
    fbb_.AddElement<int32_t>(StridedSlice::VT_BEGIN_MASK, begin_mask, 0);
  }
  void add_end_mask(int32_t end_mask) {
    fbb_.AddElement<int32_t>(StridedSlice::VT_END_MASK, end_mask, 0);
  }
  void add_shrink_axis_mask(int32_t shrink_axis_mask) {
    fbb_.AddElement<int32_t>(StridedSlice::VT_SHRINK_AXIS_MASK, shrink_axis_mask, 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(StridedSlice::VT_OUTPUT, output);
  }
  explicit StridedSliceBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  StridedSliceBuilder &operator=(const StridedSliceBuilder &);
  flatbuffers::Offset<StridedSlice> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<StridedSlice>(end);
    return o;
  }
};

inline flatbuffers::Offset<StridedSlice> CreateStridedSlice(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> starts = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> ends = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
    int32_t begin_mask = 0,
    int32_t end_mask = 0,
    int32_t shrink_axis_mask = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  StridedSliceBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_shrink_axis_mask(shrink_axis_mask);
  builder_.add_end_mask(end_mask);
  builder_.add_begin_mask(begin_mask);
  builder_.add_strides(strides);
  builder_.add_ends(ends);
  builder_.add_starts(starts);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<StridedSlice> CreateStridedSliceDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *starts = nullptr,
    const std::vector<int32_t> *ends = nullptr,
    const std::vector<int32_t> *strides = nullptr,
    int32_t begin_mask = 0,
    int32_t end_mask = 0,
    int32_t shrink_axis_mask = 0,
    const char *output = nullptr) {
  return DNN::CreateStridedSlice(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      starts ? _fbb.CreateVector<int32_t>(*starts) : 0,
      ends ? _fbb.CreateVector<int32_t>(*ends) : 0,
      strides ? _fbb.CreateVector<int32_t>(*strides) : 0,
      begin_mask,
      end_mask,
      shrink_axis_mask,
      output ? _fbb.CreateString(output) : 0);
}

struct BatchToSpace FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_BLOCK_SIZES = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *block_sizes() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_BLOCK_SIZES);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_BLOCK_SIZES) &&
           verifier.VerifyVector(block_sizes()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct BatchToSpaceBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(BatchToSpace::VT_INPUT, input);
  }
  void add_block_sizes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes) {
    fbb_.AddOffset(BatchToSpace::VT_BLOCK_SIZES, block_sizes);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(BatchToSpace::VT_OUTPUT, output);
  }
  explicit BatchToSpaceBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  BatchToSpaceBuilder &operator=(const BatchToSpaceBuilder &);
  flatbuffers::Offset<BatchToSpace> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<BatchToSpace>(end);
    return o;
  }
};

inline flatbuffers::Offset<BatchToSpace> CreateBatchToSpace(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  BatchToSpaceBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_block_sizes(block_sizes);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<BatchToSpace> CreateBatchToSpaceDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *block_sizes = nullptr,
    const char *output = nullptr) {
  return DNN::CreateBatchToSpace(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      block_sizes ? _fbb.CreateVector<int32_t>(*block_sizes) : 0,
      output ? _fbb.CreateString(output) : 0);
}

struct SpaceToBatch FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_BLOCK_SIZES = 6,
    VT_PADS = 8,
    VT_OUTPUT = 10
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *block_sizes() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_BLOCK_SIZES);
  }
  const flatbuffers::Vector<int32_t> *pads() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_BLOCK_SIZES) &&
           verifier.VerifyVector(block_sizes()) &&
           VerifyOffset(verifier, VT_PADS) &&
           verifier.VerifyVector(pads()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct SpaceToBatchBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(SpaceToBatch::VT_INPUT, input);
  }
  void add_block_sizes(flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes) {
    fbb_.AddOffset(SpaceToBatch::VT_BLOCK_SIZES, block_sizes);
  }
  void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
    fbb_.AddOffset(SpaceToBatch::VT_PADS, pads);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(SpaceToBatch::VT_OUTPUT, output);
  }
  explicit SpaceToBatchBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SpaceToBatchBuilder &operator=(const SpaceToBatchBuilder &);
  flatbuffers::Offset<SpaceToBatch> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<SpaceToBatch>(end);
    return o;
  }
};

inline flatbuffers::Offset<SpaceToBatch> CreateSpaceToBatch(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> block_sizes = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  SpaceToBatchBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_pads(pads);
  builder_.add_block_sizes(block_sizes);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<SpaceToBatch> CreateSpaceToBatchDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *block_sizes = nullptr,
    const std::vector<int32_t> *pads = nullptr,
    const char *output = nullptr) {
  return DNN::CreateSpaceToBatch(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      block_sizes ? _fbb.CreateVector<int32_t>(*block_sizes) : 0,
      pads ? _fbb.CreateVector<int32_t>(*pads) : 0,
      output ? _fbb.CreateString(output) : 0);
}

struct Conv2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_WEIGHT = 6,
    VT_BIAS = 8,
    VT_PADS = 10,
    VT_STRIDES = 12,
    VT_FUSE = 14,
    VT_OUTPUT = 16
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *weight() const {
    return GetPointer<const flatbuffers::String *>(VT_WEIGHT);
  }
  const flatbuffers::String *bias() const {
    return GetPointer<const flatbuffers::String *>(VT_BIAS);
  }
  const flatbuffers::Vector<int32_t> *pads() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
  }
  const flatbuffers::Vector<int32_t> *strides() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDES);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyString(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyString(bias()) &&
           VerifyOffset(verifier, VT_PADS) &&
           verifier.VerifyVector(pads()) &&
           VerifyOffset(verifier, VT_STRIDES) &&
           verifier.VerifyVector(strides()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct Conv2DBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(Conv2D::VT_INPUT, input);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::String> weight) {
    fbb_.AddOffset(Conv2D::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::String> bias) {
    fbb_.AddOffset(Conv2D::VT_BIAS, bias);
  }
  void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
    fbb_.AddOffset(Conv2D::VT_PADS, pads);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides) {
    fbb_.AddOffset(Conv2D::VT_STRIDES, strides);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(Conv2D::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(Conv2D::VT_OUTPUT, output);
  }
  explicit Conv2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  Conv2DBuilder &operator=(const Conv2DBuilder &);
  flatbuffers::Offset<Conv2D> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Conv2D>(end);
    return o;
  }
};

inline flatbuffers::Offset<Conv2D> CreateConv2D(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> weight = 0,
    flatbuffers::Offset<flatbuffers::String> bias = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  Conv2DBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_strides(strides);
  builder_.add_pads(pads);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<Conv2D> CreateConv2DDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *weight = nullptr,
    const char *bias = nullptr,
    const std::vector<int32_t> *pads = nullptr,
    const std::vector<int32_t> *strides = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  return DNN::CreateConv2D(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      weight ? _fbb.CreateString(weight) : 0,
      bias ? _fbb.CreateString(bias) : 0,
      pads ? _fbb.CreateVector<int32_t>(*pads) : 0,
      strides ? _fbb.CreateVector<int32_t>(*strides) : 0,
      fuse,
      output ? _fbb.CreateString(output) : 0);
}

struct DepthwiseConv2D FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_WEIGHT = 6,
    VT_BIAS = 8,
    VT_PADS = 10,
    VT_STRIDES = 12,
    VT_MULTIPLIER = 14,
    VT_FUSE = 16,
    VT_OUTPUT = 18
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *weight() const {
    return GetPointer<const flatbuffers::String *>(VT_WEIGHT);
  }
  const flatbuffers::String *bias() const {
    return GetPointer<const flatbuffers::String *>(VT_BIAS);
  }
  const flatbuffers::Vector<int32_t> *pads() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
  }
  const flatbuffers::Vector<int32_t> *strides() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDES);
  }
  int32_t multiplier() const {
    return GetField<int32_t>(VT_MULTIPLIER, 0);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyString(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyString(bias()) &&
           VerifyOffset(verifier, VT_PADS) &&
           verifier.VerifyVector(pads()) &&
           VerifyOffset(verifier, VT_STRIDES) &&
           verifier.VerifyVector(strides()) &&
           VerifyField<int32_t>(verifier, VT_MULTIPLIER) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct DepthwiseConv2DBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(DepthwiseConv2D::VT_INPUT, input);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::String> weight) {
    fbb_.AddOffset(DepthwiseConv2D::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::String> bias) {
    fbb_.AddOffset(DepthwiseConv2D::VT_BIAS, bias);
  }
  void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
    fbb_.AddOffset(DepthwiseConv2D::VT_PADS, pads);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides) {
    fbb_.AddOffset(DepthwiseConv2D::VT_STRIDES, strides);
  }
  void add_multiplier(int32_t multiplier) {
    fbb_.AddElement<int32_t>(DepthwiseConv2D::VT_MULTIPLIER, multiplier, 0);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(DepthwiseConv2D::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(DepthwiseConv2D::VT_OUTPUT, output);
  }
  explicit DepthwiseConv2DBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  DepthwiseConv2DBuilder &operator=(const DepthwiseConv2DBuilder &);
  flatbuffers::Offset<DepthwiseConv2D> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<DepthwiseConv2D>(end);
    return o;
  }
};

inline flatbuffers::Offset<DepthwiseConv2D> CreateDepthwiseConv2D(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> weight = 0,
    flatbuffers::Offset<flatbuffers::String> bias = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
    int32_t multiplier = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  DepthwiseConv2DBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_multiplier(multiplier);
  builder_.add_strides(strides);
  builder_.add_pads(pads);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<DepthwiseConv2D> CreateDepthwiseConv2DDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *weight = nullptr,
    const char *bias = nullptr,
    const std::vector<int32_t> *pads = nullptr,
    const std::vector<int32_t> *strides = nullptr,
    int32_t multiplier = 0,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  return DNN::CreateDepthwiseConv2D(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      weight ? _fbb.CreateString(weight) : 0,
      bias ? _fbb.CreateString(bias) : 0,
      pads ? _fbb.CreateVector<int32_t>(*pads) : 0,
      strides ? _fbb.CreateVector<int32_t>(*strides) : 0,
      multiplier,
      fuse,
      output ? _fbb.CreateString(output) : 0);
}

struct AvePool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_KERNEL_SHAPE = 6,
    VT_PADS = 8,
    VT_STRIDES = 10,
    VT_FUSE = 12,
    VT_OUTPUT = 14
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *kernel_shape() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_KERNEL_SHAPE);
  }
  const flatbuffers::Vector<int32_t> *pads() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
  }
  const flatbuffers::Vector<int32_t> *strides() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDES);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_KERNEL_SHAPE) &&
           verifier.VerifyVector(kernel_shape()) &&
           VerifyOffset(verifier, VT_PADS) &&
           verifier.VerifyVector(pads()) &&
           VerifyOffset(verifier, VT_STRIDES) &&
           verifier.VerifyVector(strides()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct AvePoolBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(AvePool::VT_INPUT, input);
  }
  void add_kernel_shape(flatbuffers::Offset<flatbuffers::Vector<int32_t>> kernel_shape) {
    fbb_.AddOffset(AvePool::VT_KERNEL_SHAPE, kernel_shape);
  }
  void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
    fbb_.AddOffset(AvePool::VT_PADS, pads);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides) {
    fbb_.AddOffset(AvePool::VT_STRIDES, strides);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(AvePool::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(AvePool::VT_OUTPUT, output);
  }
  explicit AvePoolBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  AvePoolBuilder &operator=(const AvePoolBuilder &);
  flatbuffers::Offset<AvePool> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<AvePool>(end);
    return o;
  }
};

inline flatbuffers::Offset<AvePool> CreateAvePool(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> kernel_shape = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  AvePoolBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_strides(strides);
  builder_.add_pads(pads);
  builder_.add_kernel_shape(kernel_shape);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<AvePool> CreateAvePoolDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *kernel_shape = nullptr,
    const std::vector<int32_t> *pads = nullptr,
    const std::vector<int32_t> *strides = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  return DNN::CreateAvePool(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      kernel_shape ? _fbb.CreateVector<int32_t>(*kernel_shape) : 0,
      pads ? _fbb.CreateVector<int32_t>(*pads) : 0,
      strides ? _fbb.CreateVector<int32_t>(*strides) : 0,
      fuse,
      output ? _fbb.CreateString(output) : 0);
}

struct MaxPool FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_KERNEL_SHAPE = 6,
    VT_PADS = 8,
    VT_STRIDES = 10,
    VT_FUSE = 12,
    VT_OUTPUT = 14
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::Vector<int32_t> *kernel_shape() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_KERNEL_SHAPE);
  }
  const flatbuffers::Vector<int32_t> *pads() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_PADS);
  }
  const flatbuffers::Vector<int32_t> *strides() const {
    return GetPointer<const flatbuffers::Vector<int32_t> *>(VT_STRIDES);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_KERNEL_SHAPE) &&
           verifier.VerifyVector(kernel_shape()) &&
           VerifyOffset(verifier, VT_PADS) &&
           verifier.VerifyVector(pads()) &&
           VerifyOffset(verifier, VT_STRIDES) &&
           verifier.VerifyVector(strides()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct MaxPoolBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(MaxPool::VT_INPUT, input);
  }
  void add_kernel_shape(flatbuffers::Offset<flatbuffers::Vector<int32_t>> kernel_shape) {
    fbb_.AddOffset(MaxPool::VT_KERNEL_SHAPE, kernel_shape);
  }
  void add_pads(flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads) {
    fbb_.AddOffset(MaxPool::VT_PADS, pads);
  }
  void add_strides(flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides) {
    fbb_.AddOffset(MaxPool::VT_STRIDES, strides);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(MaxPool::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(MaxPool::VT_OUTPUT, output);
  }
  explicit MaxPoolBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  MaxPoolBuilder &operator=(const MaxPoolBuilder &);
  flatbuffers::Offset<MaxPool> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<MaxPool>(end);
    return o;
  }
};

inline flatbuffers::Offset<MaxPool> CreateMaxPool(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> kernel_shape = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> pads = 0,
    flatbuffers::Offset<flatbuffers::Vector<int32_t>> strides = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  MaxPoolBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_strides(strides);
  builder_.add_pads(pads);
  builder_.add_kernel_shape(kernel_shape);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<MaxPool> CreateMaxPoolDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const std::vector<int32_t> *kernel_shape = nullptr,
    const std::vector<int32_t> *pads = nullptr,
    const std::vector<int32_t> *strides = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  return DNN::CreateMaxPool(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      kernel_shape ? _fbb.CreateVector<int32_t>(*kernel_shape) : 0,
      pads ? _fbb.CreateVector<int32_t>(*pads) : 0,
      strides ? _fbb.CreateVector<int32_t>(*strides) : 0,
      fuse,
      output ? _fbb.CreateString(output) : 0);
}

struct Relu FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct ReluBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(Relu::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(Relu::VT_OUTPUT, output);
  }
  explicit ReluBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ReluBuilder &operator=(const ReluBuilder &);
  flatbuffers::Offset<Relu> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Relu>(end);
    return o;
  }
};

inline flatbuffers::Offset<Relu> CreateRelu(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  ReluBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<Relu> CreateReluDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  return DNN::CreateRelu(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      output ? _fbb.CreateString(output) : 0);
}

struct Softmax FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_OUTPUT = 6
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct SoftmaxBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(Softmax::VT_INPUT, input);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(Softmax::VT_OUTPUT, output);
  }
  explicit SoftmaxBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  SoftmaxBuilder &operator=(const SoftmaxBuilder &);
  flatbuffers::Offset<Softmax> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Softmax>(end);
    return o;
  }
};

inline flatbuffers::Offset<Softmax> CreateSoftmax(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  SoftmaxBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input(input);
  return builder_.Finish();
}

inline flatbuffers::Offset<Softmax> CreateSoftmaxDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *output = nullptr) {
  return DNN::CreateSoftmax(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      output ? _fbb.CreateString(output) : 0);
}

struct FC FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT = 4,
    VT_WEIGHT = 6,
    VT_BIAS = 8,
    VT_FUSE = 10,
    VT_OUTPUT = 12
  };
  const flatbuffers::String *input() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT);
  }
  const flatbuffers::String *weight() const {
    return GetPointer<const flatbuffers::String *>(VT_WEIGHT);
  }
  const flatbuffers::String *bias() const {
    return GetPointer<const flatbuffers::String *>(VT_BIAS);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT) &&
           verifier.VerifyString(input()) &&
           VerifyOffset(verifier, VT_WEIGHT) &&
           verifier.VerifyString(weight()) &&
           VerifyOffset(verifier, VT_BIAS) &&
           verifier.VerifyString(bias()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct FCBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input(flatbuffers::Offset<flatbuffers::String> input) {
    fbb_.AddOffset(FC::VT_INPUT, input);
  }
  void add_weight(flatbuffers::Offset<flatbuffers::String> weight) {
    fbb_.AddOffset(FC::VT_WEIGHT, weight);
  }
  void add_bias(flatbuffers::Offset<flatbuffers::String> bias) {
    fbb_.AddOffset(FC::VT_BIAS, bias);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(FC::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(FC::VT_OUTPUT, output);
  }
  explicit FCBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  FCBuilder &operator=(const FCBuilder &);
  flatbuffers::Offset<FC> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<FC>(end);
    return o;
  }
};

inline flatbuffers::Offset<FC> CreateFC(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input = 0,
    flatbuffers::Offset<flatbuffers::String> weight = 0,
    flatbuffers::Offset<flatbuffers::String> bias = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  FCBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_bias(bias);
  builder_.add_weight(weight);
  builder_.add_input(input);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<FC> CreateFCDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input = nullptr,
    const char *weight = nullptr,
    const char *bias = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  return DNN::CreateFC(
      _fbb,
      input ? _fbb.CreateString(input) : 0,
      weight ? _fbb.CreateString(weight) : 0,
      bias ? _fbb.CreateString(bias) : 0,
      fuse,
      output ? _fbb.CreateString(output) : 0);
}

struct Add FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUT1 = 4,
    VT_INPUT2 = 6,
    VT_FUSE = 8,
    VT_OUTPUT = 10
  };
  const flatbuffers::String *input1() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT1);
  }
  const flatbuffers::String *input2() const {
    return GetPointer<const flatbuffers::String *>(VT_INPUT2);
  }
  FuseCode fuse() const {
    return static_cast<FuseCode>(GetField<int8_t>(VT_FUSE, 0));
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUT1) &&
           verifier.VerifyString(input1()) &&
           VerifyOffset(verifier, VT_INPUT2) &&
           verifier.VerifyString(input2()) &&
           VerifyField<int8_t>(verifier, VT_FUSE) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct AddBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_input1(flatbuffers::Offset<flatbuffers::String> input1) {
    fbb_.AddOffset(Add::VT_INPUT1, input1);
  }
  void add_input2(flatbuffers::Offset<flatbuffers::String> input2) {
    fbb_.AddOffset(Add::VT_INPUT2, input2);
  }
  void add_fuse(FuseCode fuse) {
    fbb_.AddElement<int8_t>(Add::VT_FUSE, static_cast<int8_t>(fuse), 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(Add::VT_OUTPUT, output);
  }
  explicit AddBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  AddBuilder &operator=(const AddBuilder &);
  flatbuffers::Offset<Add> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Add>(end);
    return o;
  }
};

inline flatbuffers::Offset<Add> CreateAdd(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::String> input1 = 0,
    flatbuffers::Offset<flatbuffers::String> input2 = 0,
    FuseCode fuse = FuseCode::None,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  AddBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_input2(input2);
  builder_.add_input1(input1);
  builder_.add_fuse(fuse);
  return builder_.Finish();
}

inline flatbuffers::Offset<Add> CreateAddDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const char *input1 = nullptr,
    const char *input2 = nullptr,
    FuseCode fuse = FuseCode::None,
    const char *output = nullptr) {
  return DNN::CreateAdd(
      _fbb,
      input1 ? _fbb.CreateString(input1) : 0,
      input2 ? _fbb.CreateString(input2) : 0,
      fuse,
      output ? _fbb.CreateString(output) : 0);
}

struct Concat FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_INPUTS = 4,
    VT_AXIS = 6,
    VT_OUTPUT = 8
  };
  const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *inputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>> *>(VT_INPUTS);
  }
  int32_t axis() const {
    return GetField<int32_t>(VT_AXIS, 0);
  }
  const flatbuffers::String *output() const {
    return GetPointer<const flatbuffers::String *>(VT_OUTPUT);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_INPUTS) &&
           verifier.VerifyVector(inputs()) &&
           verifier.VerifyVectorOfStrings(inputs()) &&
           VerifyField<int32_t>(verifier, VT_AXIS) &&
           VerifyOffset(verifier, VT_OUTPUT) &&
           verifier.VerifyString(output()) &&
           verifier.EndTable();
  }
};

struct ConcatBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> inputs) {
    fbb_.AddOffset(Concat::VT_INPUTS, inputs);
  }
  void add_axis(int32_t axis) {
    fbb_.AddElement<int32_t>(Concat::VT_AXIS, axis, 0);
  }
  void add_output(flatbuffers::Offset<flatbuffers::String> output) {
    fbb_.AddOffset(Concat::VT_OUTPUT, output);
  }
  explicit ConcatBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ConcatBuilder &operator=(const ConcatBuilder &);
  flatbuffers::Offset<Concat> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Concat>(end);
    return o;
  }
};

inline flatbuffers::Offset<Concat> CreateConcat(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<flatbuffers::String>>> inputs = 0,
    int32_t axis = 0,
    flatbuffers::Offset<flatbuffers::String> output = 0) {
  ConcatBuilder builder_(_fbb);
  builder_.add_output(output);
  builder_.add_axis(axis);
  builder_.add_inputs(inputs);
  return builder_.Finish();
}

inline flatbuffers::Offset<Concat> CreateConcatDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<flatbuffers::Offset<flatbuffers::String>> *inputs = nullptr,
    int32_t axis = 0,
    const char *output = nullptr) {
  return DNN::CreateConcat(
      _fbb,
      inputs ? _fbb.CreateVector<flatbuffers::Offset<flatbuffers::String>>(*inputs) : 0,
      axis,
      output ? _fbb.CreateString(output) : 0);
}

struct Layer FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_TYPE = 4,
    VT_CONV2D_PARAM = 6,
    VT_AVEPOOL_PARAM = 8,
    VT_MAXPOOL_PARAM = 10,
    VT_RELU_PARAM = 12,
    VT_SOFTMAX_PARAM = 14,
    VT_FC_PARAM = 16,
    VT_ADD_PARAM = 18,
    VT_CONCAT_PARAM = 20,
    VT_DEPTHWISE_CONV2D_PARAM = 22,
    VT_BATCH_TO_SPACE_PARAM = 24,
    VT_SPACE_TO_BATCH_PARAM = 26,
    VT_STRIDED_SLICE_PARAM = 28
  };
  LayerType type() const {
    return static_cast<LayerType>(GetField<int8_t>(VT_TYPE, 0));
  }
  const Conv2D *conv2d_param() const {
    return GetPointer<const Conv2D *>(VT_CONV2D_PARAM);
  }
  const AvePool *avepool_param() const {
    return GetPointer<const AvePool *>(VT_AVEPOOL_PARAM);
  }
  const MaxPool *maxpool_param() const {
    return GetPointer<const MaxPool *>(VT_MAXPOOL_PARAM);
  }
  const Relu *relu_param() const {
    return GetPointer<const Relu *>(VT_RELU_PARAM);
  }
  const Softmax *softmax_param() const {
    return GetPointer<const Softmax *>(VT_SOFTMAX_PARAM);
  }
  const FC *fc_param() const {
    return GetPointer<const FC *>(VT_FC_PARAM);
  }
  const Add *add_param() const {
    return GetPointer<const Add *>(VT_ADD_PARAM);
  }
  const Concat *concat_param() const {
    return GetPointer<const Concat *>(VT_CONCAT_PARAM);
  }
  const DepthwiseConv2D *depthwise_conv2d_param() const {
    return GetPointer<const DepthwiseConv2D *>(VT_DEPTHWISE_CONV2D_PARAM);
  }
  const BatchToSpace *batch_to_space_param() const {
    return GetPointer<const BatchToSpace *>(VT_BATCH_TO_SPACE_PARAM);
  }
  const SpaceToBatch *space_to_batch_param() const {
    return GetPointer<const SpaceToBatch *>(VT_SPACE_TO_BATCH_PARAM);
  }
  const StridedSlice *strided_slice_param() const {
    return GetPointer<const StridedSlice *>(VT_STRIDED_SLICE_PARAM);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyField<int8_t>(verifier, VT_TYPE) &&
           VerifyOffset(verifier, VT_CONV2D_PARAM) &&
           verifier.VerifyTable(conv2d_param()) &&
           VerifyOffset(verifier, VT_AVEPOOL_PARAM) &&
           verifier.VerifyTable(avepool_param()) &&
           VerifyOffset(verifier, VT_MAXPOOL_PARAM) &&
           verifier.VerifyTable(maxpool_param()) &&
           VerifyOffset(verifier, VT_RELU_PARAM) &&
           verifier.VerifyTable(relu_param()) &&
           VerifyOffset(verifier, VT_SOFTMAX_PARAM) &&
           verifier.VerifyTable(softmax_param()) &&
           VerifyOffset(verifier, VT_FC_PARAM) &&
           verifier.VerifyTable(fc_param()) &&
           VerifyOffset(verifier, VT_ADD_PARAM) &&
           verifier.VerifyTable(add_param()) &&
           VerifyOffset(verifier, VT_CONCAT_PARAM) &&
           verifier.VerifyTable(concat_param()) &&
           VerifyOffset(verifier, VT_DEPTHWISE_CONV2D_PARAM) &&
           verifier.VerifyTable(depthwise_conv2d_param()) &&
           VerifyOffset(verifier, VT_BATCH_TO_SPACE_PARAM) &&
           verifier.VerifyTable(batch_to_space_param()) &&
           VerifyOffset(verifier, VT_SPACE_TO_BATCH_PARAM) &&
           verifier.VerifyTable(space_to_batch_param()) &&
           VerifyOffset(verifier, VT_STRIDED_SLICE_PARAM) &&
           verifier.VerifyTable(strided_slice_param()) &&
           verifier.EndTable();
  }
};

struct LayerBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_type(LayerType type) {
    fbb_.AddElement<int8_t>(Layer::VT_TYPE, static_cast<int8_t>(type), 0);
  }
  void add_conv2d_param(flatbuffers::Offset<Conv2D> conv2d_param) {
    fbb_.AddOffset(Layer::VT_CONV2D_PARAM, conv2d_param);
  }
  void add_avepool_param(flatbuffers::Offset<AvePool> avepool_param) {
    fbb_.AddOffset(Layer::VT_AVEPOOL_PARAM, avepool_param);
  }
  void add_maxpool_param(flatbuffers::Offset<MaxPool> maxpool_param) {
    fbb_.AddOffset(Layer::VT_MAXPOOL_PARAM, maxpool_param);
  }
  void add_relu_param(flatbuffers::Offset<Relu> relu_param) {
    fbb_.AddOffset(Layer::VT_RELU_PARAM, relu_param);
  }
  void add_softmax_param(flatbuffers::Offset<Softmax> softmax_param) {
    fbb_.AddOffset(Layer::VT_SOFTMAX_PARAM, softmax_param);
  }
  void add_fc_param(flatbuffers::Offset<FC> fc_param) {
    fbb_.AddOffset(Layer::VT_FC_PARAM, fc_param);
  }
  void add_add_param(flatbuffers::Offset<Add> add_param) {
    fbb_.AddOffset(Layer::VT_ADD_PARAM, add_param);
  }
  void add_concat_param(flatbuffers::Offset<Concat> concat_param) {
    fbb_.AddOffset(Layer::VT_CONCAT_PARAM, concat_param);
  }
  void add_depthwise_conv2d_param(flatbuffers::Offset<DepthwiseConv2D> depthwise_conv2d_param) {
    fbb_.AddOffset(Layer::VT_DEPTHWISE_CONV2D_PARAM, depthwise_conv2d_param);
  }
  void add_batch_to_space_param(flatbuffers::Offset<BatchToSpace> batch_to_space_param) {
    fbb_.AddOffset(Layer::VT_BATCH_TO_SPACE_PARAM, batch_to_space_param);
  }
  void add_space_to_batch_param(flatbuffers::Offset<SpaceToBatch> space_to_batch_param) {
    fbb_.AddOffset(Layer::VT_SPACE_TO_BATCH_PARAM, space_to_batch_param);
  }
  void add_strided_slice_param(flatbuffers::Offset<StridedSlice> strided_slice_param) {
    fbb_.AddOffset(Layer::VT_STRIDED_SLICE_PARAM, strided_slice_param);
  }
  explicit LayerBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  LayerBuilder &operator=(const LayerBuilder &);
  flatbuffers::Offset<Layer> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Layer>(end);
    return o;
  }
};

inline flatbuffers::Offset<Layer> CreateLayer(
    flatbuffers::FlatBufferBuilder &_fbb,
    LayerType type = LayerType::Conv2D,
    flatbuffers::Offset<Conv2D> conv2d_param = 0,
    flatbuffers::Offset<AvePool> avepool_param = 0,
    flatbuffers::Offset<MaxPool> maxpool_param = 0,
    flatbuffers::Offset<Relu> relu_param = 0,
    flatbuffers::Offset<Softmax> softmax_param = 0,
    flatbuffers::Offset<FC> fc_param = 0,
    flatbuffers::Offset<Add> add_param = 0,
    flatbuffers::Offset<Concat> concat_param = 0,
    flatbuffers::Offset<DepthwiseConv2D> depthwise_conv2d_param = 0,
    flatbuffers::Offset<BatchToSpace> batch_to_space_param = 0,
    flatbuffers::Offset<SpaceToBatch> space_to_batch_param = 0,
    flatbuffers::Offset<StridedSlice> strided_slice_param = 0) {
  LayerBuilder builder_(_fbb);
  builder_.add_strided_slice_param(strided_slice_param);
  builder_.add_space_to_batch_param(space_to_batch_param);
  builder_.add_batch_to_space_param(batch_to_space_param);
  builder_.add_depthwise_conv2d_param(depthwise_conv2d_param);
  builder_.add_concat_param(concat_param);
  builder_.add_add_param(add_param);
  builder_.add_fc_param(fc_param);
  builder_.add_softmax_param(softmax_param);
  builder_.add_relu_param(relu_param);
  builder_.add_maxpool_param(maxpool_param);
  builder_.add_avepool_param(avepool_param);
  builder_.add_conv2d_param(conv2d_param);
  builder_.add_type(type);
  return builder_.Finish();
}

struct Model FLATBUFFERS_FINAL_CLASS : private flatbuffers::Table {
  enum {
    VT_LAYERS = 4,
    VT_INITIALIZERS = 6,
    VT_INPUTS = 8
  };
  const flatbuffers::Vector<flatbuffers::Offset<Layer>> *layers() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Layer>> *>(VT_LAYERS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<Tensor>> *initializers() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Tensor>> *>(VT_INITIALIZERS);
  }
  const flatbuffers::Vector<flatbuffers::Offset<Input>> *inputs() const {
    return GetPointer<const flatbuffers::Vector<flatbuffers::Offset<Input>> *>(VT_INPUTS);
  }
  bool Verify(flatbuffers::Verifier &verifier) const {
    return VerifyTableStart(verifier) &&
           VerifyOffset(verifier, VT_LAYERS) &&
           verifier.VerifyVector(layers()) &&
           verifier.VerifyVectorOfTables(layers()) &&
           VerifyOffset(verifier, VT_INITIALIZERS) &&
           verifier.VerifyVector(initializers()) &&
           verifier.VerifyVectorOfTables(initializers()) &&
           VerifyOffset(verifier, VT_INPUTS) &&
           verifier.VerifyVector(inputs()) &&
           verifier.VerifyVectorOfTables(inputs()) &&
           verifier.EndTable();
  }
};

struct ModelBuilder {
  flatbuffers::FlatBufferBuilder &fbb_;
  flatbuffers::uoffset_t start_;
  void add_layers(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Layer>>> layers) {
    fbb_.AddOffset(Model::VT_LAYERS, layers);
  }
  void add_initializers(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Tensor>>> initializers) {
    fbb_.AddOffset(Model::VT_INITIALIZERS, initializers);
  }
  void add_inputs(flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Input>>> inputs) {
    fbb_.AddOffset(Model::VT_INPUTS, inputs);
  }
  explicit ModelBuilder(flatbuffers::FlatBufferBuilder &_fbb)
        : fbb_(_fbb) {
    start_ = fbb_.StartTable();
  }
  ModelBuilder &operator=(const ModelBuilder &);
  flatbuffers::Offset<Model> Finish() {
    const auto end = fbb_.EndTable(start_);
    auto o = flatbuffers::Offset<Model>(end);
    return o;
  }
};

inline flatbuffers::Offset<Model> CreateModel(
    flatbuffers::FlatBufferBuilder &_fbb,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Layer>>> layers = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Tensor>>> initializers = 0,
    flatbuffers::Offset<flatbuffers::Vector<flatbuffers::Offset<Input>>> inputs = 0) {
  ModelBuilder builder_(_fbb);
  builder_.add_inputs(inputs);
  builder_.add_initializers(initializers);
  builder_.add_layers(layers);
  return builder_.Finish();
}

inline flatbuffers::Offset<Model> CreateModelDirect(
    flatbuffers::FlatBufferBuilder &_fbb,
    const std::vector<flatbuffers::Offset<Layer>> *layers = nullptr,
    const std::vector<flatbuffers::Offset<Tensor>> *initializers = nullptr,
    const std::vector<flatbuffers::Offset<Input>> *inputs = nullptr) {
  return DNN::CreateModel(
      _fbb,
      layers ? _fbb.CreateVector<flatbuffers::Offset<Layer>>(*layers) : 0,
      initializers ? _fbb.CreateVector<flatbuffers::Offset<Tensor>>(*initializers) : 0,
      inputs ? _fbb.CreateVector<flatbuffers::Offset<Input>>(*inputs) : 0);
}

inline const DNN::Model *GetModel(const void *buf) {
  return flatbuffers::GetRoot<DNN::Model>(buf);
}

inline const DNN::Model *GetSizePrefixedModel(const void *buf) {
  return flatbuffers::GetSizePrefixedRoot<DNN::Model>(buf);
}

inline bool VerifyModelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifyBuffer<DNN::Model>(nullptr);
}

inline bool VerifySizePrefixedModelBuffer(
    flatbuffers::Verifier &verifier) {
  return verifier.VerifySizePrefixedBuffer<DNN::Model>(nullptr);
}

inline void FinishModelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<DNN::Model> root) {
  fbb.Finish(root);
}

inline void FinishSizePrefixedModelBuffer(
    flatbuffers::FlatBufferBuilder &fbb,
    flatbuffers::Offset<DNN::Model> root) {
  fbb.FinishSizePrefixed(root);
}

}  // namespace DNN

#endif  // FLATBUFFERS_GENERATED_DAQ_DNN_H_
